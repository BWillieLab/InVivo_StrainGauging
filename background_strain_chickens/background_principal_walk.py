# -*- coding: utf-8 -*-
"""
Created on Mon Oct 18 10:10:48 2021

@author: IVitienes
"""
import numpy as np
import os, tkinter.filedialog
import tkinter as tk
from scipy import signal
import pandas as pd
import math


# Written by Isabela Vitienes 2021

###################################################################################################################
# This code automatically analyzes segments of strain during walking to obtain peak principal strains.            #
# Code takes as input strain segments AND ginputs generated by analyzing axial strain (background_axial_walk.py   #                                                                             #
# The code is designed for data from one rosette strain gauge.                                                    #
# Outputs are saved in the same location as the input file.                                                       #
###################################################################################################################

# Input data formatting:
# You should have a list containing the segment files and the ginput files for each segment file.
# There must be a 1:1 correspondence with segment and ginput files. When selecting the files make sure list is ordered alphabetically.
# As input to this code, you should therefore select a list of files, where there is a segment followed by its ginput file. 

# LICENSE
# This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 2 of the License, or (at your option) any later version.
# This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 
# For more details: https://www.gnu.org/licenses/gpl-3.0.html.



# Get segments and ginputs
# Selection should be ordered by name, such that in the resulting list of file names, each segment is followed by its ginput file. 
Initialdir = "S:\Projects_Isabela\Current_projects\Chickens\MyStudy\Data\Flock_three\strain_gauging\exported\background"
Title = "Order by name and select all segments and ginputs"
root = tk.Tk()
root.focus_force()
ftypes=[("excel", "*.xlsx")]
paths = tk.filedialog.askopenfilenames(initialdir=Initialdir, parent=root,title=Title,filetypes=ftypes)
names = [os.path.splitext(os.path.basename(file))[0] for file in paths]
files = [paths,names]
root.withdraw()


# Divide files into segments and ginputs, matched by indices in the separate arrays.
L = len(names)
segment_names = []
segment_paths = []
ginput_names = []
ginput_paths = []
for i in range(L): 
    if L%2 == 1:
        break
    if i%2 == 0: # if even, segment
        segment_names.append(names[i])
        segment_paths.append(paths[i])
    if i%2 == 1: # if odd, ginput
        ginput_names.append(names[i])
        ginput_paths.append(paths[i])

        
# Now, work with each segment-ginput pair
results_averages = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]
Ls = len(ginput_names) 
for k in range(Ls):
    
    # Extract raw data
    df1 = pd.read_excel(segment_paths[k])
    dfs = df1.to_numpy()

    strain_index = dfs[:,0]
    strain_time = dfs[:,1]
    # *** Only need rosette strain data for principal strains, adjust channels depending on your data 
    strain1 = dfs[:,4]
    strain2 = dfs[:,6]
    strain3 = dfs[:,8]
    
    
    # Filter strains
    # *** Cutoff frequency selected to ensure that it is above the Nyquist frequency for the activities you have sampled. 
    fs = 1000  # Sampling frequency
    fc = 40  # Cut-off frequency of the filter
    w = fc / (fs / 2) # Normalize the frequency
    b, a = signal.butter(4, w, 'low')
    strain1_filt = signal.filtfilt(b, a, strain1)
    b, a = signal.butter(4, w, 'low')
    strain2_filt = signal.filtfilt(b, a, strain2)
    b, a = signal.butter(4, w, 'low')
    strain3_filt = signal.filtfilt(b, a, strain3)
    
    strains_filt = np.vstack([strain1_filt, strain2_filt, strain3_filt])
    strains_filt = np.matrix.transpose(strains_filt)
    
    # Extract ginputs
    df2 = pd.read_excel(ginput_paths[k])
    dfg = df2.to_numpy()
    
    
    # calculate raw swing strains with ginputs
    Lg = len(dfg)
    sR1 = np.mean(strain1_filt[int(dfg[0,1]):int(dfg[1,1])])
    sR2 = np.mean(strain2_filt[int(dfg[0,1]):int(dfg[1,1])])
    sR3 = np.mean(strain3_filt[int(dfg[0,1]):int(dfg[1,1])])

    # Zero the raw strains
    strain1_zeroed = strain1_filt - sR1
    strain2_zeroed = strain2_filt - sR2
    strain3_zeroed = strain3_filt - sR3
    
    # Save zeroed data
    zeroed = np.vstack([strain1_zeroed, strain2_zeroed, strain3_zeroed])
    zeroed = np.matrix.transpose(zeroed)
    name = segment_names[k]
    POI = segment_paths[k]
    filepath = POI[:-5] + "_zeroed.xlsx"
    dfresults = pd.DataFrame(zeroed)
    dfresults.to_excel(filepath)
    
    
    
    # Convert to principal strain
    
    # Method from: Biewener, 1992, "Biomechanics: Structures and Systems", Chapter 6; Biewener and Dial, J. Morph., 1995
    
    # Max and min principal strain.
    strain_pr_max = ((strain1_zeroed + strain3_zeroed) / 2) + (1/2) * np.sqrt((strain1_zeroed - strain2_zeroed)**2 + (strain2_zeroed - strain3_zeroed)**2)))
    strain_pr_min = ((strain1_zeroed + strain3_zeroed) / 2) - (1/2) * np.sqrt((strain1_zeroed - strain2_zeroed)**2 + (strain2_zeroed - strain3_zeroed)**2)))
    
    # 'theta' is angle from principal axis to axis of gauge 1 (strain1)
    # angle is CCW if positive, CW if negative
    strain_pr_theta_radians = (1 / 2) * np.arctan(((-1)*strain1_zeroed + 2 * strain2_zeroed - strain3_zeroed) / (strain1_zeroed - strain3_zeroed))
    
    # Convert angle to degrees
    strain_pr_theta = strain_pr_theta_radians * 180 / math.pi
    
    # Compute shear strain
    shear = 2 * np.sin(strain_pr_theta_radians) * np.cos(strain_pr_theta_radians) * (strain_pr_max - strain_pr_min)
    
    # Compile principal strains / angle
    strain_pr = np.vstack([strain_index, strain_time, strain1_filt, strain2_filt, strain3_filt, strain_pr_max, strain_pr_min, strain_pr_theta, shear])
    strain_pr = np.matrix.transpose(strain_pr)
    
    # Save principal strain data
    pr_path = POI[:-5] + "_principal_strain.xlsx"
    dfresultspr = pd.DataFrame(strain_pr)
    dfresultspr.to_excel(pr_path)
    
    
    ############################################################
    ### Compute derived parameters in principal strain domain ###
    ############################################################


    # Use ginputs to guide calculation of peak principal strains. Same as approach used in "background_axial_walk.py"
    # This is necessary because principal strains will not necessarilly peak when axial strain peaks (i.e. cannot convert peak axial strains to principal strain).
    
    # Extract ginputs, only care about x-coordinates
    ginputs_x = dfg[:,1]
    
    px_steps = ginputs_x[2:-2]
    
    px_step_freq = ginputs_x[-2:]
    
    no_steps = int((len(px_steps))/2)
    
    pk_max_time = np.zeros(no_steps)
    pk_max = np.zeros(no_steps)
    pk_max_theta = np.zeros(no_steps)
    pk_min_time = np.zeros(no_steps)
    pk_min = np.zeros(no_steps)
    pk_min_theta = np.zeros(no_steps)
    pk_shear = np.zeros(no_steps)

    
    for i in range(no_steps):
            
        a = int(px_steps[2*i])
        b = int(px_steps[2*i + 1])
        
        pk_max_max = np.max([strain_pr_max[a:b]])
        pk_max_min = np.min([strain_pr_max[a:b]])
        if abs(pk_max_max) > abs(pk_max_min):
            pk_max[i] = pk_max_max 
        elif abs(pk_max_max) < abs(pk_max_min):
            pk_max[i] = pk_max_min
        else:
            np.isnan(pk_max[i])
        pk_max_index = np.where(strain_pr_max[a:b] == pk_max[i])
        pk_max_time[i] = strain_time[pk_max_index]
        pk_max_theta[i] = strain_pr_theta[pk_max_index]
        pk_shear[i] = shear[pk_max_index]
        
        pk_min_max = np.max(strain_pr_min[a:b])
        pk_min_min = np.min(strain_pr_min[a:b])
        if abs(pk_min_max) > abs(pk_min_min):
            pk_min[i] = pk_min_max 
        elif abs(pk_min_max) < abs(pk_min_min):
            pk_min[i] = pk_min_min
        else:
            np.isnan(pk_min[i])
        pk_min_index = np.where(strain_pr_min[a:b] == pk_min[i])
        pk_min_time[i] = strain_time[pk_min_index]
        pk_min_theta[i] = strain_pr_theta[pk_min_index]
            
    
    results2 = np.vstack([pk_max, pk_max_theta, pk_max_time, pk_min, pk_min_theta, pk_min_time, pk_shear])
    #results2 = np.matrix.transpose(results2)
        
    savepath = POI[:-5] + "_principal_strain_results_per_step.xlsx"
        
    dfresults = pd.DataFrame(results2)
    dfresults.to_excel(savepath)
    
    
    # averages across steps
    
    step_freq = 1000*no_steps/(px_step_freq[1] - px_step_freq[0]) # Should be same as step_freq calculated with axial strains. 
    
    mean_pk_max = np.mean(pk_max)
    sd_pk_max = np.std(pk_max)
    
    mean_pk_max_theta = np.mean(pk_max_theta)
    sd_pk_max_theta = np.std(pk_max_theta)
    
    mean_pk_min = np.mean(pk_min)
    sd_pk_min = np.std(pk_min)
    
    mean_pk_min_theta = np.mean(pk_min_theta)
    sd_pk_min_theta = np.std(pk_min_theta)
    
    mean_pk_shear = np.mean(pk_shear)
    sd_pk_shear = np.mean(pk_shear)
    
    FOI = segment_names[k]
    if FOI[3] == '_':
        ID = FOI[:3]
    else:
        ID = FOI[:4]
    seg = FOI[-2:] 
    if seg[0] == '_':
        seg = seg[1:]
    
    results3 = [[ID, seg, no_steps, step_freq, mean_pk_max, mean_pk_max_theta, mean_pk_min, mean_pk_min_theta, mean_pk_shear, sd_pk_max, sd_pk_max_theta, sd_pk_min, sd_pk_min_theta, sd_pk_shear]]
    savepath = POI[:-5] + "_principal_strain_results_average.xlsx"
    dfresults3 = pd.DataFrame(results3)
    dfresults3.to_excel(savepath)
    
    results_averages = np.vstack([results_averages, results3])

# Compile results
averages = results_averages[1:,:]
#averages_transpose = np.transpose(averages)
N = len(names[0])
path = paths[0]
NN = N + 5
savepath = path[:-NN] + "_principal_walk_compiled_results.xlsx"
dfresults4 = pd.DataFrame(averages)
dfresults4.to_excel(savepath) 
    
    
    
    
    

